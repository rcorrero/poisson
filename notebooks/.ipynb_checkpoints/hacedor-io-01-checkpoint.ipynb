{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Dataset` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make filepaths\n",
    "ship_dir = '../input/'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')\n",
    "test_image_dir = os.path.join(ship_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://www.kaggle.com/windsurfer/baseline-u-net-on-pytorch\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived from: https://www.kaggle.com/windsurfer/baseline-u-net-on-pytorch\n",
    "class ShipDataset(Dataset):\n",
    "    def __init__(self, image_ids, image_masks transform=None, mode='train'):\n",
    "        grp = list(in_df.groupby('ImageId'))\n",
    "        self.image_ids = image_ids\n",
    "        self.image_masks = image_masks\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.img_transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "               \n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.image_ids[idx]\n",
    "        if self.mode == 'train':\n",
    "            rgb_path = os.path.join(train_image_dir, img_file_name)\n",
    "        else:\n",
    "            rgb_path = os.path.join(test_image_dir, img_file_name)\n",
    "        img = imread(rgb_path)\n",
    "        mask = masks_as_image(self.image_masks[idx])\n",
    "       \n",
    "        if self.transform is not None:\n",
    "            img, mask = self.transform(img, mask)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            #return self.to_float_tensor(img), self.to_float_tensor(mask)\n",
    "            #eturn img, mask\n",
    "            return self.img_transform(img), torch.from_numpy(np.moveaxis(mask, -1, 0)).float()\n",
    "        else:\n",
    "            return self.img_transform(img), str(img_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove subset of images from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.read_csv('../../airbus-dataset/train_ship_segmentations_v2.csv')\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_size(rle):\n",
    "    if type(rle) is not str:\n",
    "        return float('inf')\n",
    "    s = rle.split()\n",
    "    length = sum([int(x) for x in s[1:][::2]])\n",
    "    return length\n",
    "\n",
    "\n",
    "def filter_ids(masks, max_thresh=300, n_neg_samples = 50000):\n",
    "    # Remove duplicates using set\n",
    "    id_set_1 = set(masks.loc[masks['EncodedPixels'].apply(\n",
    "        lambda x: get_box_size(x) <= max_thresh\n",
    "        )]['ImageId'].tolist())\n",
    "#    id_set_2 = set(masks.loc[masks['EncodedPixels'].apply(\n",
    "#        lambda x: isinstance(x, str)\n",
    "#        )]['ImageId'].tolist())\n",
    "#    id_set_2 = set(masks.drop(\n",
    "#        masks[masks.EncodedPixels.notnull()].index).sample(50000).index)\n",
    "    id_set_2 = set(masks.drop(\n",
    "            masks[masks.EncodedPixels.notnull()].index\n",
    "            ).sample(n_neg_samples).ImageId.tolist())\n",
    "    \n",
    "    return list(id_set_1.union(id_set_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_thresh = 300\n",
    "n_neg_samples = 20000\n",
    "id_list = filter_ids(masks, max_thresh, n_neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(masks.drop(masks[masks.EncodedPixels.notnull()].index).sample(50000).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masks.apply(lambda m: get_box_size(m) <= max_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masks.groupby(masks.ImageId).apply(lambda g: g[g.EncodedPixels == str])\n",
    "\n",
    "#id_set_2 = masks.drop(\n",
    "#        masks[masks.EncodedPixels.notnull()].index).sample(50000).ImageId.tolist()\n",
    "#id_set_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = pd.read_csv('../../airbus-dataset/train_ship_segmentations_v2.csv')\n",
    "#masks.head()\n",
    "\n",
    "max_thresh = 300\n",
    "#def grp_function(grp, max_thresh):\n",
    "#    print(grp.EncodedPixels)\n",
    "    \n",
    "#grps = masks.groupby('ImageId')\n",
    "#grps.\n",
    "    \n",
    "\n",
    "filtered_masks = masks.groupby('ImageId').apply(lambda grp: grp.EncodedPixels.apply(lambda rle: get_box_size(rle) <= max_thresh).any()\n",
    "                                               ).reset_index(name='counts')\n",
    "#filtered_masks[filtered_masks.counts].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>198320 10 199088 10 199856 10 200624 10 201392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>254389 9 255157 17 255925 17 256693 17 257461 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231671</th>\n",
       "      <td>ffef7c3f3.jpg</td>\n",
       "      <td>476372 3 477138 5 477906 6 478674 6 479443 5 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231677</th>\n",
       "      <td>fff1bdeea.jpg</td>\n",
       "      <td>500297 3 501061 7 501827 9 502595 10 503363 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231686</th>\n",
       "      <td>fff529a0e.jpg</td>\n",
       "      <td>530576 1 531343 3 532110 5 532877 7 533646 8 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231712</th>\n",
       "      <td>fffd924fb.jpg</td>\n",
       "      <td>110011 5 110779 5 111547 5 112315 5 113083 5 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231713</th>\n",
       "      <td>fffd924fb.jpg</td>\n",
       "      <td>198440 8 199208 8 199976 8 200744 8 201512 8 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51262 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId                                      EncodedPixels\n",
       "3       000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4       000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...\n",
       "5       000194a2d.jpg  198320 10 199088 10 199856 10 200624 10 201392...\n",
       "6       000194a2d.jpg  55683 1 56451 1 57219 1 57987 1 58755 1 59523 ...\n",
       "7       000194a2d.jpg  254389 9 255157 17 255925 17 256693 17 257461 ...\n",
       "...               ...                                                ...\n",
       "231671  ffef7c3f3.jpg  476372 3 477138 5 477906 6 478674 6 479443 5 4...\n",
       "231677  fff1bdeea.jpg  500297 3 501061 7 501827 9 502595 10 503363 10...\n",
       "231686  fff529a0e.jpg  530576 1 531343 3 532110 5 532877 7 533646 8 5...\n",
       "231712  fffd924fb.jpg  110011 5 110779 5 111547 5 112315 5 113083 5 1...\n",
       "231713  fffd924fb.jpg  198440 8 199208 8 199976 8 200744 8 201512 8 2...\n",
       "\n",
       "[51262 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[masks.ImageId.isin(filtered_masks[filtered_masks.counts == True].ImageId)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that this number matches `len(id_list)`\n",
    "if masks[(masks.ImageId.isin(id_list))].groupby('ImageId').ngroups == len(id_list):\n",
    "    masks[(masks.ImageId.isin(id_list))].EncodedPixels.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Transform`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(x, mask):\n",
    "    if mask is not None:\n",
    "        mask = mask[::2, ::2]\n",
    "    return x[::2, ::2, :], mask\n",
    "    \n",
    "    \n",
    "class RandomDownsample:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "    \n",
    "    \n",
    "    def __call__(self, x, mask=None):\n",
    "        if random.random() < prob:\n",
    "            return downsample(x, mask)\n",
    "        return x, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Implementation from  https://github.com/ternaus/robot-surgery-segmentation\n",
    "\"\"\"\n",
    "\n",
    "def clip(img, dtype, maxval):\n",
    "    return np.clip(img, 0, maxval).astype(dtype)\n",
    "\n",
    "class DualCompose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        for t in self.transforms:\n",
    "            x, mask = t(x, mask)\n",
    "        return x, mask\n",
    "    \n",
    "class OneOf:\n",
    "    def __init__(self, transforms, prob=0.5):\n",
    "        self.transforms = transforms\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            t = random.choice(self.transforms)\n",
    "            t.prob = 1.\n",
    "            x, mask = t(x, mask)\n",
    "        return x, mask\n",
    "\n",
    "class OneOrOther:\n",
    "    def __init__(self, first, second, prob=0.5):\n",
    "        self.first = first\n",
    "        first.prob = 1.\n",
    "        self.second = second\n",
    "        second.prob = 1.\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            x, mask = self.first(x, mask)\n",
    "        else:\n",
    "            x, mask = self.second(x, mask)\n",
    "        return x, mask\n",
    "\n",
    "\n",
    "class ImageOnly:\n",
    "    def __init__(self, trans):\n",
    "        self.trans = trans\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        return self.trans(x), mask\n",
    "\n",
    "\n",
    "class VerticalFlip:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            img = cv2.flip(img, 0)\n",
    "            if mask is not None:\n",
    "                mask = cv2.flip(mask, 0)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class HorizontalFlip:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            img = cv2.flip(img, 1)\n",
    "            if mask is not None:\n",
    "                mask = cv2.flip(mask, 1)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class RandomFlip:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            d = random.randint(-1, 1)\n",
    "            img = cv2.flip(img, d)\n",
    "            if mask is not None:\n",
    "                mask = cv2.flip(mask, d)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class Transpose:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            img = img.transpose(1, 0, 2)\n",
    "            if mask is not None:\n",
    "                mask = mask.transpose(1, 0, 2)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class RandomRotate90:\n",
    "    def __init__(self, prob=0.5):\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            factor = random.randint(0, 4)\n",
    "            img = np.rot90(img, factor)\n",
    "            if mask is not None:\n",
    "                mask = np.rot90(mask, factor)\n",
    "        return img.copy(), mask.copy()\n",
    "\n",
    "\n",
    "class Rotate:\n",
    "    def __init__(self, limit=90, prob=0.5):\n",
    "        self.prob = prob\n",
    "        self.limit = limit\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.limit, self.limit)\n",
    "\n",
    "            height, width = img.shape[0:2]\n",
    "            mat = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1.0)\n",
    "            img = cv2.warpAffine(img, mat, (height, width),\n",
    "                                 flags=cv2.INTER_LINEAR,\n",
    "                                 borderMode=cv2.BORDER_REFLECT_101)\n",
    "            if mask is not None:\n",
    "                mask = cv2.warpAffine(mask, mat, (height, width),\n",
    "                                      flags=cv2.INTER_LINEAR,\n",
    "                                      borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class RandomCrop:\n",
    "    def __init__(self, size):\n",
    "        self.h = size[0]\n",
    "        self.w = size[1]\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        h_start = np.random.randint(0, height - self.h)\n",
    "        w_start = np.random.randint(0, width - self.w)\n",
    "\n",
    "        img = img[h_start: h_start + self.h, w_start: w_start + self.w,:]\n",
    "\n",
    "        assert img.shape[0] == self.h\n",
    "        assert img.shape[1] == self.w\n",
    "\n",
    "        if mask is not None:\n",
    "            if mask.ndim == 2:\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "            mask = mask[h_start: h_start + self.h, w_start: w_start + self.w,:]\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class Shift:\n",
    "    def __init__(self, limit=4, prob=.5):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            limit = self.limit\n",
    "            dx = round(random.uniform(-limit, limit))\n",
    "            dy = round(random.uniform(-limit, limit))\n",
    "\n",
    "            height, width, channel = img.shape\n",
    "            y1 = limit + 1 + dy\n",
    "            y2 = y1 + height\n",
    "            x1 = limit + 1 + dx\n",
    "            x2 = x1 + width\n",
    "\n",
    "            img1 = cv2.copyMakeBorder(img, limit + 1, limit + 1, limit + 1, limit + 1,\n",
    "                                      borderType=cv2.BORDER_REFLECT_101)\n",
    "            img = img1[y1:y2, x1:x2, :]\n",
    "            if mask is not None:\n",
    "                msk1 = cv2.copyMakeBorder(mask, limit + 1, limit + 1, limit + 1, limit + 1,\n",
    "                                          borderType=cv2.BORDER_REFLECT_101)\n",
    "                mask = msk1[y1:y2, x1:x2, :]\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class ShiftScale:\n",
    "    def __init__(self, limit=4, prob=.25):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        limit = self.limit\n",
    "        if random.random() < self.prob:\n",
    "            height, width, channel = img.shape\n",
    "            assert (width == height)\n",
    "            size0 = width\n",
    "            size1 = width + 2 * limit\n",
    "            size = round(random.uniform(size0, size1))\n",
    "\n",
    "            dx = round(random.uniform(0, size1 - size))\n",
    "            dy = round(random.uniform(0, size1 - size))\n",
    "\n",
    "            y1 = dy\n",
    "            y2 = y1 + size\n",
    "            x1 = dx\n",
    "            x2 = x1 + size\n",
    "\n",
    "            img1 = cv2.copyMakeBorder(img, limit, limit, limit, limit, borderType=cv2.BORDER_REFLECT_101)\n",
    "            img = (img1[y1:y2, x1:x2, :] if size == size0\n",
    "            else cv2.resize(img1[y1:y2, x1:x2, :], (size0, size0), interpolation=cv2.INTER_LINEAR))\n",
    "\n",
    "            if mask is not None:\n",
    "                msk1 = cv2.copyMakeBorder(mask, limit, limit, limit, limit, borderType=cv2.BORDER_REFLECT_101)\n",
    "                mask = (msk1[y1:y2, x1:x2, :] if size == size0\n",
    "                else cv2.resize(msk1[y1:y2, x1:x2, :], (size0, size0), interpolation=cv2.INTER_LINEAR))\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class ShiftScaleRotate:\n",
    "    def __init__(self, shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, prob=0.5):\n",
    "        self.shift_limit = shift_limit\n",
    "        self.scale_limit = scale_limit\n",
    "        self.rotate_limit = rotate_limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        if random.random() < self.prob:\n",
    "            height, width, channel = img.shape\n",
    "\n",
    "            angle = random.uniform(-self.rotate_limit, self.rotate_limit)\n",
    "            scale = random.uniform(1 - self.scale_limit, 1 + self.scale_limit)\n",
    "            dx = round(random.uniform(-self.shift_limit, self.shift_limit)) * width\n",
    "            dy = round(random.uniform(-self.shift_limit, self.shift_limit)) * height\n",
    "\n",
    "            cc = math.cos(angle / 180 * math.pi) * scale\n",
    "            ss = math.sin(angle / 180 * math.pi) * scale\n",
    "            rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "            box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "            box1 = box0 - np.array([width / 2, height / 2])\n",
    "            box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "            box0 = box0.astype(np.float32)\n",
    "            box1 = box1.astype(np.float32)\n",
    "            mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "            img = cv2.warpPerspective(img, mat, (width, height),\n",
    "                                      flags=cv2.INTER_LINEAR,\n",
    "                                      borderMode=cv2.BORDER_REFLECT_101)\n",
    "            if mask is not None:\n",
    "                mask = cv2.warpPerspective(mask, mat, (width, height),\n",
    "                                           flags=cv2.INTER_NEAREST,\n",
    "                                           borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "class CenterCrop:\n",
    "    def __init__(self, size):\n",
    "        self.height = size[0]\n",
    "        self.width = size[1]\n",
    "\n",
    "    def __call__(self, img, mask=None):\n",
    "        h, w, c = img.shape\n",
    "        dy = (h - self.height) // 2\n",
    "        dx = (w - self.width) // 2\n",
    "        y1 = dy\n",
    "        y2 = y1 + self.height\n",
    "        x1 = dx\n",
    "        x2 = x1 + self.width\n",
    "        img = img[y1:y2, x1:x2,:]\n",
    "        if mask is not None:\n",
    "            if mask.ndim == 2:\n",
    "                mask = np.expand_dims(mask, axis=2)\n",
    "            mask = mask[y1:y2, x1:x2,:]\n",
    "\n",
    "        return img, mask\n",
    "    \n",
    "class RandomBrightness:\n",
    "    def __init__(self, limit=0.1, prob=0.5):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            alpha = 1.0 + self.limit * random.uniform(-1, 1)\n",
    "\n",
    "            maxval = np.max(img[..., :3])\n",
    "            dtype = img.dtype\n",
    "            img[..., :3] = clip(alpha * img[..., :3], dtype, maxval)\n",
    "        return img\n",
    "\n",
    "\n",
    "class RandomContrast:\n",
    "    def __init__(self, limit=.1, prob=.5):\n",
    "        self.limit = limit\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            alpha = 1.0 + self.limit * random.uniform(-1, 1)\n",
    "\n",
    "            gray = cv2.cvtColor(img[:, :, :3], cv2.COLOR_BGR2GRAY)\n",
    "            gray = (3.0 * (1.0 - alpha) / gray.size) * np.sum(gray)\n",
    "            maxval = np.max(img[..., :3])\n",
    "            dtype = img.dtype\n",
    "            img[:, :, :3] = clip(alpha * img[:, :, :3] + gray, dtype, maxval)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we're ready to combine the code from [here](https://www.kaggle.com/windsurfer/baseline-u-net-on-pytorch) with the downsample transformer and the modified `ShipDataset` to finish the training framework. Once this is done we need to think about what parameters need to be monitored during training and how to structure the training process so that the computation required is not wasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test tranches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "unique_img_ids = masks.groupby('ImageId').size().reset_index(name='counts')\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.05, \n",
    "                 stratify = unique_img_ids['counts'],\n",
    "                 random_state=42\n",
    "                )\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_size(rle):\n",
    "    if type(rle) is not str:\n",
    "        return float('inf')\n",
    "    s = rle.split()\n",
    "    length = sum([int(x) for x in s[1:][::2]])\n",
    "    return length\n",
    "\n",
    "\n",
    "def filter_ids(masks, max_thresh=300, n_neg_samples = 50000):\n",
    "    # Remove duplicates using set\n",
    "    id_set_1 = set(masks.loc[masks['EncodedPixels'].apply(\n",
    "        lambda x: get_box_size(x) <= max_thresh\n",
    "        )]['ImageId'].tolist())\n",
    "#    id_set_2 = set(masks.loc[masks['EncodedPixels'].apply(\n",
    "#        lambda x: isinstance(x, str)\n",
    "#        )]['ImageId'].tolist())\n",
    "#    id_set_2 = set(masks.drop(\n",
    "#        masks[masks.EncodedPixels.notnull()].index).sample(50000).index)\n",
    "    id_set_2 = set(masks.drop(\n",
    "            masks[masks.EncodedPixels.notnull()].index\n",
    "            ).sample(n_neg_samples).ImageId.tolist())\n",
    "    \n",
    "    return list(id_set_1.union(id_set_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-bf4144dba4a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m train_ids, valid_ids = train_test_split(unique_img_ids, \n\u001b[1;32m      8\u001b[0m                  \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                  \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_img_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                  \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 )\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "max_thresh = 300\n",
    "n_neg_samples = 20000\n",
    "unique_img_ids = filter_ids(masks, max_thresh, n_neg_samples)\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.05, \n",
    "                 stratify = unique_img_ids['counts'],\n",
    "                 random_state=42\n",
    "                )\n",
    "#train_df = pd.merge(masks, train_ids)\n",
    "#valid_df = pd.merge(masks, valid_ids)\n",
    "#print(train_df.shape[0], 'training masks')\n",
    "#print(valid_df.shape[0], 'validation masks'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
